# cancerolog
It detects various types of cancer with high accuracy by analyzing different image sets such as X-Ray, PNG, JPEG and Ultrasound, available on portable devices, with artificial intelligence algorithms.

 With the power of deep learning algorithms, images are processed and information is presented to the user in real time with advanced mobile interface support in the mobile application.
This project aims to make significant contributions to the healthcare sector by offering an innovative approach to cancer diagnosis and classification. It performs real-time cancer detection and classification via mobile devices and has the ability to analyze various image types (X-Ray, Png, Jpeg, Ultrasound).

Using Artificial Intelligence algorithms, it is possible to process these images in real time and determine the probability of cancer types.

This technology plans to increase public health awareness and provide a decision support system to healthcare professionals by helping individuals detect disease risk at early stages.
The large data set formed by combining the data sets contains 6,940 images in total. The data classes in the set are respectively;

Cancerous Lung (4273),
Healthy Lung (1583 grains),
Cancerous Skin (85 grains),
Healthy Skin (204 items),
Healthy Breast (133),
Benign Tumorous Breast (445 grains),
Breast with Malignant Tumor (218 grains).


At the beginning of the project, the aim was to analyze images taken on mobile devices, primarily with the help of cameras. Then, the analysis of the images stored in the portable devices was integrated into the application.


Deep Learning Algorithms: Convolutional Neural Networks (CNN) algorithms were used to analyze the images.
Real-Time Analysis: Optimized models have been developed and integrated into mobile devices to perform real-time analysis on mobile devices.
Image Processing Techniques: Various image processing techniques have been applied to process different types of images such as X-Ray, Png, Jpeg and Ultrasound.
Computer Vision: Cellular changes that are difficult to analyze even with the human eye are tested and determined in a computer environment, and early diagnosis and treatment processes are thus facilitated.

In the mobile application, users can upload images to the application using their mobile device's camera or on their device.
Uploaded or captured images are analyzed in real time.
As a result of the analyzed images, the application provides the user with information about the possible cancer diagnosis and cancer type.

Status of Achieving Goals
The mobile application was successfully presented to the user by capturing and analyzing cancer images.
Contribution was made to early diagnosis and treatment processes.
challenges
Language and library incompatibilities, incompleteness and disorganization of datasets were identified as the biggest challenges. Resolving issues with TensorFlow Lite and Flutter integration also required additional effort.

Future Work
Database Integration: A database system can be developed to store screening results and health data.
Advanced Image Analysis: Advanced modules can be added for object detection and processing of different data types.
Data Sharing and Personalized Recommendations: Artificial intelligence systems can be developed to share health data with doctors and provide personalized recommendations.
Data Collection for Research and Development: Research and development studies can be supported with anonymized data.


![Uploading Screenshot_20240620_172510_com.example.medical_app.jpgâ€¦]()
